{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Quiz Generator\n",
    "\n",
    "This notebook demonstrates an AI-powered quiz generator using LangChain and OpenAI's GPT-3.5-turbo model.\n",
    "\n",
    "## Features\n",
    "- Generates customized quizzes based on user-specified categories (Geography, Science, Art)\n",
    "- Uses a knowledge base of facts about various subjects\n",
    "- Includes evaluation functions to test the quiz generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API tokens for our 3rd party APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_circle_api_key\n",
    "cci_api_key = get_circle_api_key()\n",
    "\n",
    "from utils import get_gh_api_key\n",
    "gh_api_key = get_gh_api_key()\n",
    "\n",
    "from utils import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up our github branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quiz-generator'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_repo_name\n",
    "course_repo = get_repo_name()\n",
    "course_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_branch\n",
    "course_branch = get_branch()\n",
    "course_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sample Application: AI-powered Quiz Generator\n",
    "\n",
    "We are going to build an AI powered quiz generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset for the quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{question}\"\n",
    "\n",
    "quiz_bank = \"\"\"1. Subject: Leonardo DaVinci\n",
    "   Categories: Art, Science\n",
    "   Facts:\n",
    "    - Painted the Mona Lisa\n",
    "    - Studied zoology, anatomy, geology, optics\n",
    "    - Designed a flying machine\n",
    "  \n",
    "2. Subject: Paris\n",
    "   Categories: Art, Geography\n",
    "   Facts:\n",
    "    - Location of the Louvre, the museum where the Mona Lisa is displayed\n",
    "    - Capital of France\n",
    "    - Most populous city in France\n",
    "    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\n",
    "\n",
    "3. Subject: Telescopes\n",
    "   Category: Science\n",
    "   Facts:\n",
    "    - Device to observe different objects\n",
    "    - The first refracting telescopes were invented in the Netherlands in the 17th Century\n",
    "    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\n",
    "\n",
    "4. Subject: Starry Night\n",
    "   Category: Art\n",
    "   Facts:\n",
    "    - Painted by Vincent van Gogh in 1889\n",
    "    - Captures the east-facing view of van Gogh's room in Saint-Rémy-de-Provence\n",
    "\n",
    "5. Subject: Physics\n",
    "   Category: Science\n",
    "   Facts:\n",
    "    - The sun doesn't change color during sunset.\n",
    "    - Water slows the speed of light\n",
    "    - The Eiffel Tower in Paris is taller in the summer than the winter due to expansion of the metal.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "\n",
    "prompt_template = f\"\"\"\n",
    "Follow these steps to generate a customized quiz for the user.\n",
    "The question will be delimited with four hashtags i.e {delimiter}\n",
    "\n",
    "The user will provide a category that they want to create a quiz for. Any questions included in the quiz\n",
    "should only refer to the category.\n",
    "\n",
    "Step 1:{delimiter} First identify the category user is asking about from the following list:\n",
    "* Geography\n",
    "* Science\n",
    "* Art\n",
    "\n",
    "Step 2:{delimiter} Determine the subjects to generate questions about. The list of topics are below:\n",
    "\n",
    "{quiz_bank}\n",
    "\n",
    "Pick up to two subjects that fit the user's category. \n",
    "\n",
    "Step 3:{delimiter} Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\n",
    "\n",
    "Use the following format for the quiz:\n",
    "Question 1:{delimiter} <question 1>\n",
    "\n",
    "Question 2:{delimiter} <question 2>\n",
    "\n",
    "Question 3:{delimiter} <question 3>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LangChain to build the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"\\nFollow these steps to generate a customized quiz for the user.\\nThe question will be delimited with four hashtags i.e ####\\n\\nThe user will provide a category that they want to create a quiz for. Any questions included in the quiz\\nshould only refer to the category.\\n\\nStep 1:#### First identify the category user is asking about from the following list:\\n* Geography\\n* Science\\n* Art\\n\\nStep 2:#### Determine the subjects to generate questions about. The list of topics are below:\\n\\n1. Subject: Leonardo DaVinci\\n   Categories: Art, Science\\n   Facts:\\n    - Painted the Mona Lisa\\n    - Studied zoology, anatomy, geology, optics\\n    - Designed a flying machine\\n\\n2. Subject: Paris\\n   Categories: Art, Geography\\n   Facts:\\n    - Location of the Louvre, the museum where the Mona Lisa is displayed\\n    - Capital of France\\n    - Most populous city in France\\n    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\\n\\n3. Subject: Telescopes\\n   Category: Science\\n   Facts:\\n    - Device to observe different objects\\n    - The first refracting telescopes were invented in the Netherlands in the 17th Century\\n    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\\n\\n4. Subject: Starry Night\\n   Category: Art\\n   Facts:\\n    - Painted by Vincent van Gogh in 1889\\n    - Captures the east-facing view of van Gogh's room in Saint-Rémy-de-Provence\\n\\n5. Subject: Physics\\n   Category: Science\\n   Facts:\\n    - The sun doesn't change color during sunset.\\n    - Water slows the speed of light\\n    - The Eiffel Tower in Paris is taller in the summer than the winter due to expansion of the metal.\\n\\nPick up to two subjects that fit the user's category. \\n\\nStep 3:#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\\n\\nUse the following format for the quiz:\\nQuestion 1:#### <question 1>\\n\\nQuestion 2:#### <question 2>\\n\\nQuestion 3:#### <question 3>\\n\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"human\", prompt_template)])\n",
    "# print to observe the content or generated object\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x112aa83b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x113008350>, root_client=<openai.OpenAI object at 0x111eaf2f0>, root_async_client=<openai.AsyncOpenAI object at 0x112aa8320>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up an output parser\n",
    "\n",
    "Set up an output parser in LangChain that converts the LLM response into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the pieces using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"\\nFollow these steps to generate a customized quiz for the user.\\nThe question will be delimited with four hashtags i.e ####\\n\\nThe user will provide a category that they want to create a quiz for. Any questions included in the quiz\\nshould only refer to the category.\\n\\nStep 1:#### First identify the category user is asking about from the following list:\\n* Geography\\n* Science\\n* Art\\n\\nStep 2:#### Determine the subjects to generate questions about. The list of topics are below:\\n\\n1. Subject: Leonardo DaVinci\\n   Categories: Art, Science\\n   Facts:\\n    - Painted the Mona Lisa\\n    - Studied zoology, anatomy, geology, optics\\n    - Designed a flying machine\\n\\n2. Subject: Paris\\n   Categories: Art, Geography\\n   Facts:\\n    - Location of the Louvre, the museum where the Mona Lisa is displayed\\n    - Capital of France\\n    - Most populous city in France\\n    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\\n\\n3. Subject: Telescopes\\n   Category: Science\\n   Facts:\\n    - Device to observe different objects\\n    - The first refracting telescopes were invented in the Netherlands in the 17th Century\\n    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\\n\\n4. Subject: Starry Night\\n   Category: Art\\n   Facts:\\n    - Painted by Vincent van Gogh in 1889\\n    - Captures the east-facing view of van Gogh's room in Saint-Rémy-de-Provence\\n\\n5. Subject: Physics\\n   Category: Science\\n   Facts:\\n    - The sun doesn't change color during sunset.\\n    - Water slows the speed of light\\n    - The Eiffel Tower in Paris is taller in the summer than the winter due to expansion of the metal.\\n\\nPick up to two subjects that fit the user's category. \\n\\nStep 3:#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\\n\\nUse the following format for the quiz:\\nQuestion 1:#### <question 1>\\n\\nQuestion 2:#### <question 2>\\n\\nQuestion 3:#### <question 3>\\n\\n\"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x112aa83b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x113008350>, root_client=<openai.OpenAI object at 0x111eaf2f0>, root_async_client=<openai.AsyncOpenAI object at 0x112aa8320>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | output_parser\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the reusable `assistant_chain` function\n",
    "\n",
    "This function puts together all steps above into a reusable component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant_chain(\n",
    "    system_message,\n",
    "    human_template=\"{question}\",\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    output_parser=StrOutputParser()):\n",
    "  \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "    return chat_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations\n",
    "\n",
    "Now let's create evaluation functions to test our quiz generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function: Expected Words\n",
    "\n",
    "Create the function `eval_expected_words` to check if the generated quiz contains expected keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_expected_words(\n",
    "    system_message,\n",
    "    question,\n",
    "    expected_words,\n",
    "    human_template=\"{question}\",\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    output_parser=StrOutputParser()):\n",
    "    \n",
    "    assistant = assistant_chain(\n",
    "        system_message,\n",
    "        human_template,\n",
    "        llm,\n",
    "        output_parser)\n",
    "    \n",
    "    answer = assistant.invoke({\"question\": question})\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    assert any(word in answer.lower() \\\n",
    "               for word in expected_words), \\\n",
    "        f\"Expected the assistant questions to include \\\n",
    "        '{expected_words}', but it did not\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Generate a quiz about science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Generate a quiz about science.\"\n",
    "expected_words = [\"davinci\", \"telescope\", \"physics\", \"curie\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:#### First identify the category user is asking about from the following list:\n",
      "* Geography\n",
      "* Science\n",
      "* Art\n",
      "\n",
      "User's Category: Science\n",
      "\n",
      "Step 2:#### Determine the subjects to generate questions about. The list of topics are below:\n",
      "\n",
      "1. Subject: Telescopes\n",
      "   Category: Science\n",
      "   Facts:\n",
      "    - Device to observe different objects\n",
      "    - The first refracting telescopes were invented in the Netherlands in the 17th Century\n",
      "    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\n",
      "\n",
      "2. Subject: Physics\n",
      "   Category: Science\n",
      "   Facts:\n",
      "    - The sun doesn't change color during sunset.\n",
      "    - Water slows the speed of light\n",
      "    - The Eiffel Tower in Paris is taller in the summer than the winter due to expansion of the metal.\n",
      "\n",
      "Selected Subjects: Telescopes, Physics\n",
      "\n",
      "Step 3:#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\n",
      "\n",
      "Question 1:#### What is the James Webb space telescope known for?\n",
      "a) Inventing the first refracting telescope\n",
      "b) Using a gold-berillyum mirror\n",
      "c) Discovering the expansion of the Eiffel Tower\n",
      "d) Observing the sun's color change during sunset\n",
      "\n",
      "Question 2:#### How does water affect the speed of light according to physics?\n",
      "a) Speeds up the light\n",
      "b) Slows down the light\n",
      "c) Changes the color of light\n",
      "d) Has no effect on the speed of light\n",
      "\n",
      "Question 3:#### Why is the Eiffel Tower taller in the summer than in the winter?\n",
      "a) Due to the change in the Earth's rotation\n",
      "b) Because of the weight of the tourists\n",
      "c) Expansion of the metal in the summer\n",
      "d) It is an optical illusion\n"
     ]
    }
   ],
   "source": [
    "eval_expected_words(\n",
    "    prompt_template,\n",
    "    question,\n",
    "    expected_words\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function: Refusal Test\n",
    "\n",
    "Create the function `evaluate_refusal` to define a failing test case where the app should decline to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_refusal(\n",
    "    system_message,\n",
    "    question,\n",
    "    decline_response,\n",
    "    human_template=\"{question}\", \n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    output_parser=StrOutputParser()):\n",
    "    \n",
    "    assistant = assistant_chain(\n",
    "        system_message,\n",
    "        human_template,\n",
    "        llm,\n",
    "        output_parser)\n",
    "  \n",
    "    answer = assistant.invoke({\"question\": question})\n",
    "    print(answer)\n",
    "  \n",
    "    assert decline_response.lower() in answer.lower(), \\\n",
    "        f\"Expected the bot to decline with \\\n",
    "        '{decline_response}' got {answer}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a bad request (should be refused)\n",
    "\n",
    "This question asks about Rome, which is not in our allowed categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Generate a quiz about Rome.\"\n",
    "decline_response = \"I'm sorry\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the refusal evaluation\n",
    "\n",
    "**Note:** The following function call will throw an exception because the model doesn't refuse to generate quizzes about Rome (it's not explicitly configured to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### First identify the category user is asking about from the following list:\n",
      "* Geography\n",
      "* Science\n",
      "* Art\n",
      "\n",
      "Since Rome falls under the category of Geography, let's select a relevant subject for the quiz.\n",
      "\n",
      "#### Determine the subjects to generate questions about. The list of topics are below:\n",
      "\n",
      "1. Subject: Paris\n",
      "   Categories: Art, Geography\n",
      "   Facts:\n",
      "    - Location of the Louvre, the museum where the Mona Lisa is displayed\n",
      "    - Capital of France\n",
      "    - Most populous city in France\n",
      "    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\n",
      "\n",
      "2. Subject: Telescopes\n",
      "   Category: Science\n",
      "   Facts:\n",
      "    - Device to observe different objects\n",
      "    - The first refracting telescopes were invented in the Netherlands in the 17th Century\n",
      "    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\n",
      "\n",
      "I will generate a quiz based on the subject of Paris, which is related to Geography.\n",
      "\n",
      "#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\n",
      "\n",
      "Question 1:#### What is the capital of France?\n",
      "Question 2:#### Where can the Mona Lisa be found?\n",
      "Question 3:#### Who discovered Radium and Polonium in Paris?\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected the bot to decline with         'I'm sorry' got #### First identify the category user is asking about from the following list:\n* Geography\n* Science\n* Art\n\nSince Rome falls under the category of Geography, let's select a relevant subject for the quiz.\n\n#### Determine the subjects to generate questions about. The list of topics are below:\n\n1. Subject: Paris\n   Categories: Art, Geography\n   Facts:\n    - Location of the Louvre, the museum where the Mona Lisa is displayed\n    - Capital of France\n    - Most populous city in France\n    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\n\n2. Subject: Telescopes\n   Category: Science\n   Facts:\n    - Device to observe different objects\n    - The first refracting telescopes were invented in the Netherlands in the 17th Century\n    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\n\nI will generate a quiz based on the subject of Paris, which is related to Geography.\n\n#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\n\nQuestion 1:#### What is the capital of France?\nQuestion 2:#### Where can the Mona Lisa be found?\nQuestion 3:#### Who discovered Radium and Polonium in Paris?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate_refusal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecline_response\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mevaluate_refusal\u001b[39m\u001b[34m(system_message, question, decline_response, human_template, llm, output_parser)\u001b[39m\n\u001b[32m     15\u001b[39m answer = assistant.invoke({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question})\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m decline_response.lower() \u001b[38;5;129;01min\u001b[39;00m answer.lower(), \\\n\u001b[32m     19\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected the bot to decline with \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecline_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Expected the bot to decline with         'I'm sorry' got #### First identify the category user is asking about from the following list:\n* Geography\n* Science\n* Art\n\nSince Rome falls under the category of Geography, let's select a relevant subject for the quiz.\n\n#### Determine the subjects to generate questions about. The list of topics are below:\n\n1. Subject: Paris\n   Categories: Art, Geography\n   Facts:\n    - Location of the Louvre, the museum where the Mona Lisa is displayed\n    - Capital of France\n    - Most populous city in France\n    - Where Radium and Polonium were discovered by scientists Marie and Pierre Curie\n\n2. Subject: Telescopes\n   Category: Science\n   Facts:\n    - Device to observe different objects\n    - The first refracting telescopes were invented in the Netherlands in the 17th Century\n    - The James Webb space telescope is the largest telescope in space. It uses a gold-berillyum mirror\n\nI will generate a quiz based on the subject of Paris, which is related to Geography.\n\n#### Generate a quiz for the user. Based on the selected subjects generate 3 questions for the user using the facts about the subject.\n\nQuestion 1:#### What is the capital of France?\nQuestion 2:#### Where can the Mona Lisa be found?\nQuestion 3:#### Who discovered Radium and Polonium in Paris?"
     ]
    }
   ],
   "source": [
    "evaluate_refusal(\n",
    "    prompt_template,\n",
    "    question,\n",
    "    decline_response\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
